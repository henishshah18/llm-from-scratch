{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4e6206",
   "metadata": {},
   "source": [
    "# 07 - Gradient Descent Optimization\n",
    "\n",
    "Gradient descent is the fundamental algorithm for training neural networks, including LLMs and transformers. It updates model parameters to minimize the loss function by following the direction of steepest descent (the negative gradient).\n",
    "\n",
    "In this notebook, you'll scaffold the steps of gradient descent, from the basic algorithm to its use in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585fa0c3",
   "metadata": {},
   "source": [
    "## üßÆ What is Gradient Descent?\n",
    "\n",
    "Gradient descent iteratively updates parameters to minimize a loss function:\n",
    "\n",
    "$$ \\theta \\leftarrow \\theta - \\eta \\nabla L(\\theta) $$\n",
    "\n",
    "where $\\theta$ are the parameters, $\\eta$ is the learning rate, and $\\nabla L(\\theta)$ is the gradient of the loss.\n",
    "\n",
    "**LLM/Transformer Context:**\n",
    "- Every parameter in an LLM is updated using gradient descent or its variants during training.\n",
    "\n",
    "### Task:\n",
    "- Scaffold a function to perform a single gradient descent update step for a parameter vector.\n",
    "- Add a docstring explaining its role in LLM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b06ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_step(params, grads, lr):\n",
    "    \"\"\"\n",
    "    Perform a single gradient descent update step.\n",
    "    In LLMs, this is used to update weights and biases after computing gradients.\n",
    "    Args:\n",
    "        params (np.ndarray): Current parameter values.\n",
    "        grads (np.ndarray): Gradients of the loss w.r.t. parameters.\n",
    "        lr (float): Learning rate.\n",
    "    Returns:\n",
    "        np.ndarray: Updated parameters.\n",
    "    \"\"\"\n",
    "    # TODO: Update params using gradient descent\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47442c1f",
   "metadata": {},
   "source": [
    "## üîÅ Gradient Descent for Neural Network Training\n",
    "\n",
    "In practice, gradient descent is applied repeatedly over many epochs to train a neural network.\n",
    "\n",
    "**LLM/Transformer Context:**\n",
    "- LLMs are trained for millions of steps using this process, often with large batches of data.\n",
    "\n",
    "### Task:\n",
    "- Scaffold a function to perform gradient descent over multiple epochs for a simple model.\n",
    "- Add a docstring explaining each step and its relevance to LLM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_gradient_descent(params, compute_loss_and_grads, lr, epochs):\n",
    "    \"\"\"\n",
    "    Train a model using gradient descent for a given number of epochs.\n",
    "    In LLMs, this process is repeated for millions of steps to optimize all parameters.\n",
    "    Args:\n",
    "        params (np.ndarray): Initial parameter values.\n",
    "        compute_loss_and_grads (callable): Function that returns (loss, grads) for current params.\n",
    "        lr (float): Learning rate.\n",
    "        epochs (int): Number of training epochs.\n",
    "    Returns:\n",
    "        np.ndarray: Trained parameters.\n",
    "    \"\"\"\n",
    "    # TODO: Implement the training loop (compute loss, compute grads, update params)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edac4ff6",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Learning Rate and Convergence\n",
    "\n",
    "The learning rate ($\\eta$) controls the step size in gradient descent. Too large, and the model may diverge; too small, and training is slow.\n",
    "\n",
    "**LLM/Transformer Context:**\n",
    "- Careful tuning of the learning rate is critical for stable and efficient LLM training.\n",
    "\n",
    "### Task:\n",
    "- Scaffold a function to experiment with different learning rates and observe their effect on convergence.\n",
    "- Add a docstring explaining why this matters for LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_learning_rates(params, compute_loss_and_grads, lrs, epochs):\n",
    "    \"\"\"\n",
    "    Experiment with different learning rates and observe convergence behavior.\n",
    "    In LLMs, learning rate schedules and tuning are essential for good performance.\n",
    "    Args:\n",
    "        params (np.ndarray): Initial parameter values.\n",
    "        compute_loss_and_grads (callable): Function that returns (loss, grads) for current params.\n",
    "        lrs (list): List of learning rates to try.\n",
    "        epochs (int): Number of epochs for each run.\n",
    "    Returns:\n",
    "        dict: Mapping from learning rate to final loss.\n",
    "    \"\"\"\n",
    "    # TODO: Run training for each learning rate and record final loss\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718b571",
   "metadata": {},
   "source": [
    "## üß† Final Summary: Gradient Descent in LLMs\n",
    "\n",
    "- Gradient descent is the core optimization algorithm for training all neural networks, including LLMs and transformers.\n",
    "- Understanding how parameters are updated and how learning rate affects convergence is key to successful model training.\n",
    "- In the next notebook, you'll explore advanced optimizers that improve on basic gradient descent for faster and more stable training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
