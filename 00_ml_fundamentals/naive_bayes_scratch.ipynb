{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes from Scratch\n",
    "\n",
    "Naive Bayes is a family of simple yet powerful probabilistic classifiers based on Bayes‚Äô theorem and the assumption of feature independence. It is widely used for text classification and as a baseline in many ML tasks.\n",
    "\n",
    "In this notebook, you'll scaffold the steps to implement Naive Bayes from scratch, including the core math, training, prediction, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Bayes‚Äô Theorem Refresher\n",
    "\n",
    "Bayes‚Äô theorem relates conditional and marginal probabilities of random events:\n",
    "\n",
    "$$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)} $$\n",
    "\n",
    "### Task:\n",
    "- Scaffold a function to compute Bayes‚Äô theorem for given probabilities.\n",
    "- Add a docstring explaining its use in Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def bayes_theorem(P_B_given_A, P_A, P_B):\n",
    "    \"\"\"\n",
    "    Compute P(A|B) using Bayes‚Äô theorem.\n",
    "    Args:\n",
    "        P_B_given_A (float): P(B|A)\n",
    "        P_A (float): P(A)\n",
    "        P_B (float): P(B)\n",
    "    Returns:\n",
    "        float: P(A|B)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Bayes‚Äô theorem\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Training: Estimate Priors and Likelihoods\n",
    "\n",
    "Naive Bayes learns class priors and feature likelihoods from the training data.\n",
    "\n",
    "### Task:\n",
    "- Scaffold functions to estimate class priors and feature likelihoods for categorical data (Multinomial/Bernoulli NB).\n",
    "- Add docstrings explaining their use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def estimate_class_priors(y):\n",
    "    \"\"\"\n",
    "    Estimate class prior probabilities from labels.\n",
    "    Args:\n",
    "        y (np.ndarray): Array of class labels (n_samples,)\n",
    "    Returns:\n",
    "        dict: Mapping from class to prior probability\n",
    "    \"\"\"\n",
    "    # TODO: Estimate class priors\n",
    "    pass\n",
    "\n",
    "def estimate_likelihoods(X, y):\n",
    "    \"\"\"\n",
    "    Estimate feature likelihoods P(x|y) for each class (for categorical features).\n",
    "    Args:\n",
    "        X (np.ndarray): Feature matrix (n_samples x n_features)\n",
    "        y (np.ndarray): Class labels (n_samples,)\n",
    "    Returns:\n",
    "        dict: Nested dict of likelihoods {class: {feature: likelihood}}\n",
    "    \"\"\"\n",
    "    # TODO: Estimate feature likelihoods\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Laplace Smoothing\n",
    "\n",
    "Laplace (additive) smoothing prevents zero probabilities for unseen features.\n",
    "\n",
    "### Task:\n",
    "- Scaffold a function to apply Laplace smoothing to likelihood estimates.\n",
    "- Add a docstring explaining its importance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def laplace_smoothing(count, total, num_classes, alpha=1):\n",
    "    \"\"\"\n",
    "    Apply Laplace smoothing to probability estimates.\n",
    "    Args:\n",
    "        count (int): Count of feature/class occurrence\n",
    "        total (int): Total count for class\n",
    "        num_classes (int): Number of possible feature values\n",
    "        alpha (float): Smoothing parameter (default=1)\n",
    "    Returns:\n",
    "        float: Smoothed probability\n",
    "    \"\"\"\n",
    "    # TODO: Apply Laplace smoothing\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Prediction: Posterior Probability & Log Probabilities\n",
    "\n",
    "Naive Bayes predicts the class with the highest posterior probability, often using log probabilities for numerical stability.\n",
    "\n",
    "### Task:\n",
    "- Scaffold a function to compute log posterior probabilities for each class given a sample.\n",
    "- Scaffold a function to predict the class label.\n",
    "- Add docstrings explaining their use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_log_posterior(x, class_priors, likelihoods):\n",
    "    \"\"\"\n",
    "    Compute log posterior probability for each class given a sample.\n",
    "    Args:\n",
    "        x (np.ndarray): Feature vector (n_features,)\n",
    "        class_priors (dict): Class prior probabilities\n",
    "        likelihoods (dict): Feature likelihoods\n",
    "    Returns:\n",
    "        dict: Mapping from class to log posterior\n",
    "    \"\"\"\n",
    "    # TODO: Compute log posterior for each class\n",
    "    pass\n",
    "\n",
    "def predict_naive_bayes(x, class_priors, likelihoods):\n",
    "    \"\"\"\n",
    "    Predict class label for a sample using Naive Bayes.\n",
    "    Args:\n",
    "        x (np.ndarray): Feature vector (n_features,)\n",
    "        class_priors (dict): Class prior probabilities\n",
    "        likelihoods (dict): Feature likelihoods\n",
    "    Returns:\n",
    "        int or str: Predicted class label\n",
    "    \"\"\"\n",
    "    # TODO: Predict class label\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training and Evaluation Loop\n",
    "\n",
    "Train the Naive Bayes model on a dataset and evaluate its accuracy.\n",
    "\n",
    "### Task:\n",
    "- Scaffold a function to train the model (estimate priors and likelihoods).\n",
    "- Scaffold a function to compute accuracy on a test set.\n",
    "- Add docstrings explaining their use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_naive_bayes(X, y):\n",
    "    \"\"\"\n",
    "    Train Naive Bayes model (estimate priors and likelihoods).\n",
    "    Args:\n",
    "        X (np.ndarray): Feature matrix\n",
    "        y (np.ndarray): Class labels\n",
    "    Returns:\n",
    "        tuple: (class_priors, likelihoods)\n",
    "    \"\"\"\n",
    "    # TODO: Train model\n",
    "    pass\n",
    "\n",
    "def compute_accuracy_naive_bayes(X, y, class_priors, likelihoods):\n",
    "    \"\"\"\n",
    "    Compute accuracy of Naive Bayes model on a dataset.\n",
    "    Args:\n",
    "        X (np.ndarray): Feature matrix\n",
    "        y (np.ndarray): True labels\n",
    "        class_priors (dict): Class prior probabilities\n",
    "        likelihoods (dict): Feature likelihoods\n",
    "    Returns:\n",
    "        float: Accuracy (0 to 1)\n",
    "    \"\"\"\n",
    "    # TODO: Compute accuracy\n",
    "    pass"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Final Summary: Naive Bayes in ML\n",
    "\n",
    "- Naive Bayes is a simple, fast, and effective classifier for many tasks, especially text classification.\n",
    "- Understanding its math and assumptions is essential for ML interviews and practical applications.\n",
    "- The probabilistic reasoning in Naive Bayes is foundational for more advanced models and LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
